# -*- coding: utf-8 -*-
"""Proyecto 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K8EFuwkoc9l9O-dOpJPc_UqWkrVBXvRB
"""

# -----------------------
# IMPORT DATA
# -----------------------

import pandas as pd
import numpy as np

import kagglehub
from kagglehub import KaggleDatasetAdapter

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report,
    roc_auc_score,
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score
)

file_path = "german_credit_data.csv"

df = kagglehub.load_dataset(
    KaggleDatasetAdapter.PANDAS,
    "kabure/german-credit-data-with-risk",
    file_path
)


# --------
# CLEANING
# --------

data = df.copy()

data["Saving accounts"]  = data["Saving accounts"].fillna("missing")
data["Checking account"] = data["Checking account"].fillna("missing")

data.drop(columns=["Unnamed: 0", "Sex"], inplace=True)


# ------------------------
# CONVERT TO NUMBERS
# ------------------------

data["Housing"] = data["Housing"].map({"free": 0, "rent": 1, "own": 2})

data["Saving accounts"] = data["Saving accounts"].map({
    "missing": 0,
    "little": 1,
    "moderate": 2,
    "quite rich": 3,
    "rich": 4
})

data["Checking account"] = data["Checking account"].map({
    "missing": 0,
    "little": 1,
    "moderate": 2,
    "rich": 3
})

data["Risk"] = data["Risk"].map({"bad": 0, "good": 1})

diccionario = {
    "radio/TV": "Hogar",
    "furniture/equipment": "Hogar",
    "domestic appliances": "Hogar",
    "repairs": "Hogar",
    "education": "Negocios_Edu",
    "business": "Negocios_Edu",
    "car": "Automovil",
    "vacation/others": "Otros"
}

data["Purpose"] = data["Purpose"].map(diccionario)
data["Purpose"] = data["Purpose"].fillna("Otros")

data = pd.get_dummies(
    data,
    columns=["Purpose"],
    prefix="Purp",
    drop_first=True
)

data = data.replace({True: 1, False: 0})


# ------------
# LOGIT MODEL
# ------------

X = data.drop("Risk", axis=1)
y = data["Risk"]

x_train, x_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled  = scaler.transform(x_test)

logit = LogisticRegression(max_iter=1000)
logit.fit(x_train_scaled, y_train)

y_pred_logit = logit.predict(x_test_scaled)
y_proba_logit = logit.predict_proba(x_test_scaled)[:, 1]

# CHANGE THRESHOLD (STRICKTIER POLITIC)

threshold = 0.67
y_pred_logit_07 = (y_proba_logit >= threshold).astype(int)


# --------------------
# RANDOM FOREST MODEL
# --------------------
rf = RandomForestClassifier(
    n_estimators=300,
    max_depth=6,
    min_samples_leaf=10,
    random_state=42,
    n_jobs=-1,
    class_weight= "balanced"
)

rf.fit(x_train, y_train)

y_pred_rf = rf.predict(x_test)
y_proba_rf = rf.predict_proba(x_test)[:, 1]

threshold = 0.67
y_pred_rf_067 = (y_proba_rf >= threshold).astype(int)


# ------------------
# SHOW RESULTS
# ------------------

def evaluar_modelo(y_real, y_pred, y_proba, nombre):
    tn, fp, fn, tp = confusion_matrix(y_real, y_pred).ravel()
    return {
        "Modelo": nombre,
        "ROC-AUC": roc_auc_score(y_real, y_proba),
        "Accuracy": accuracy_score(y_real, y_pred),
        "Precision": precision_score(y_real, y_pred),
        "Recall": recall_score(y_real, y_pred),
        "VN": tn,
        "FP": fp,
        "FN": fn,
        "VP": tp
    }

resumen_datos = [
    evaluar_modelo(y_test, y_pred_logit, y_proba_logit, "Logit (0.5)"),
    evaluar_modelo(y_test, y_pred_logit_07, y_proba_logit, f"Logit ({threshold})"),
    evaluar_modelo(y_test, y_pred_rf, y_proba_rf, "RF (0.5)"),
    evaluar_modelo(y_test, y_pred_rf_067, y_proba_rf, f"RF ({threshold})")
]

df_final = pd.DataFrame(resumen_datos)

pd.options.display.float_format = '{:.3f}'.format

df_final
